{
  "stac_version": "1.0.0",
  "stac_extensions": [
    "https://stac-extensions.github.io/table/v1.2.0/schema.json"
  ],
  "type": "Feature",
  "id": "hotdeck",
  "bbox": [
    [
      -156.6194,
      71.2824,
      -66.7987,
      71.2824
    ]
  ],
  "geometry": {
    "type": "MultiPoint",
    "coordinates": [
      [-82.0084, 29.676],
      [-82.0177, 29.6878],
      [-87.7982, 32.5415],
      [-84.4374, 31.1854],
      [-96.6038, 39.1051],
      [-83.5038, 35.6904],
      [-77.9832, 39.0956],
      [-87.4077, 32.9604],
      [-78.1473, 38.8943],
      [-97.7823, 33.3785],
      [-111.5081, 33.751],
      [-88.1589, 31.8534],
      [-102.4471, 39.7582],
      [-72.3295, 42.4719],
      [-122.1655, 44.2596],
      [-111.7979, 40.7839],
      [-119.0274, 36.9559],
      [-110.5871, 44.9501],
      [-105.5442, 40.035],
      [-105.9154, 39.8914],
      [-119.2575, 37.0597]
    ]
  },
  "properties": {
    "description": "\nmodel info: Uses a hot deck approach: - Take the latest observation/forecast. - Past observations from around the same window of the season are collected. - Values close to the latest observation/forecast are collected. - One of these is randomly sampled. - Its \"tomorrow\" observation is used as the forecast. - Repeat until forecast at step h.\n\nSites: BARC, SUGG, BLWA, FLNT, KING, LECO, LEWI, MAYF, POSE, PRIN, SYCA, TOMB, ARIK, HOPB, MCRA, REDB, TECR, BLDE, COMO, WLOU, BIGC\n\nVariables: Daily Water_temperature, Daily Dissolved_oxygen",
    "start_datetime": "2024-02-28",
    "end_datetime": "2024-04-05",
    "providers": [
      {
        "url": "pending",
        "name": "pending",
        "roles": [
          "producer",
          "processor",
          "licensor"
        ]
      },
      {
        "url": "https://www.ecoforecastprojectvt.org",
        "name": "Ecoforecast Challenge",
        "roles": [
          "host"
        ]
      }
    ],
    "license": "CC0-1.0",
    "keywords": [
      "Forecasting",
      "neon4cast",
      "Daily Water_temperature",
      "Daily Dissolved_oxygen"
    ],
    "table:columns": [
      {
        "name": "reference_datetime",
        "type": "timestamp[us, tz=UTC]",
        "description": "datetime that the forecast was initiated (horizon = 0)"
      },
      {
        "name": "site_id",
        "type": "string",
        "description": "For forecasts that are not on a spatial grid, use of a site dimension that maps to a more detailed geometry (points, polygons, etc.) is allowable. In general this would be documented in the external metadata (e.g., alook-up table that provides lon and lat); however in netCDF this could be handled by the CF Discrete Sampling Geometry data model."
      },
      {
        "name": "datetime",
        "type": "timestamp[us, tz=UTC]",
        "description": "datetime of the forecasted value (ISO 8601)"
      },
      {
        "name": "family",
        "type": "string",
        "description": "For ensembles: “ensemble.” Default value if unspecified For probability distributions: Name of the statistical distribution associated with the reported statistics. The “sample” distribution is synonymous with “ensemble.” For summary statistics: “summary.”If this dimension does not vary, it is permissible to specify family as a variable attribute if the file format being used supports this (e.g.,netCDF)."
      },
      {
        "name": "pub_datetime",
        "type": "timestamp[us, tz=UTC]",
        "description": "datetime that forecast was submitted"
      },
      {
        "name": "observation",
        "type": "double",
        "description": "observed value for variable"
      },
      {
        "name": "crps",
        "type": "double",
        "description": "crps forecast score"
      },
      {
        "name": "logs",
        "type": "double",
        "description": "logs forecast score"
      },
      {
        "name": "mean",
        "type": "double",
        "description": "mean forecast prediction"
      },
      {
        "name": "median",
        "type": "double",
        "description": "median forecast prediction"
      },
      {
        "name": "sd",
        "type": "double",
        "description": "standard deviation forecasts"
      },
      {
        "name": "quantile97.5",
        "type": "double",
        "description": "upper 97.5 percentile value of forecast"
      },
      {
        "name": "quantile02.5",
        "type": "double",
        "description": "upper 2.5 percentile value of forecast"
      },
      {
        "name": "quantile90",
        "type": "double",
        "description": "upper 90 percentile value of forecast"
      },
      {
        "name": "quantile10",
        "type": "double",
        "description": "upper 10 percentile value of forecast"
      },
      {
        "name": "project_id",
        "type": "string",
        "description": "unique project identifier"
      },
      {
        "name": "duration",
        "type": "string",
        "description": "temporal duration of forecast (hourly = PT1H, daily = P1D, etc.); follows ISO 8601 duration convention"
      },
      {
        "name": "variable",
        "type": "string",
        "description": "name of forecasted variable"
      },
      {
        "name": "model_id",
        "type": "string",
        "description": "unique model identifier"
      },
      {
        "name": "date",
        "type": "string",
        "description": "ISO 8601 (ISO 2019) date of the predicted value; follows CF convention http://cfconventions.org/cf-conventions/cf-conventions.html#time-coordinate. This variable was called time before v0.5of the EFI convention. For time-integrated variables (e.g., cumulative net primary productivity), one should specify the start_datetime and end_datetime as two variables, instead of the single datetime. If this is not provided the datetime is assumed to be the MIDPOINT of the integration period."
      }
    ]
  },
  "collection": "scores",
  "links": [
    {
      "rel": "collection",
      "href": "../collection.json",
      "type": "application/json",
      "title": "hotdeck"
    },
    {
      "rel": "root",
      "href": "../../../catalog.json",
      "type": "application/json",
      "title": "Forecast Catalog"
    },
    {
      "rel": "parent",
      "href": "../collection.json",
      "type": "application/json",
      "title": "hotdeck"
    },
    {
      "rel": "self",
      "href": "hotdeck.json",
      "type": "application/json",
      "title": "Model Forecast"
    },
    {
      "rel": "item",
      "href": "https://github.com/swpease/hotdeckfc",
      "type": "text/html",
      "title": "Link for Model Code"
    }
  ],
  "assets": {
    "1": {
      "type": "application/json",
      "title": "Model Metadata",
      "href": "https://sdsc.osn.xsede.org/bio230014-bucket01/challenges/metadata/model_id/hotdeck.json",
      "description": "Use `jsonlite::fromJSON()` to download the model metadata JSON file. This R code will return metadata provided during the model registration.\n      \n\n### R\n\n```{r}\n# Use code below\n\nmodel_metadata <- jsonlite::fromJSON(\"https://sdsc.osn.xsede.org/bio230014-bucket01/challenges/metadata/model_id/hotdeck.json\")\n\n"
    },
    "2": {
      "type": "text/html",
      "title": "Link for Model Code",
      "href": "https://github.com/swpease/hotdeckfc",
      "description": "The link to the model code provided by the model submission team"
    },
    "3": {
      "type": "application/x-parquet",
      "title": "Database Access for Daily Water_temperature",
      "href": "s3://anonymous@bio230014-bucket01/challenges/scores/parquet/project_id=neon4cast/duration=P1D/variable=temperature/model_id=hotdeck?endpoint_override=sdsc.osn.xsede.org",
      "description": "Use `arrow` for remote access to the database. This R code will return results for this variable and model combination.\n\n### R\n\n```{r}\n# Use code below\n\nall_results <- arrow::open_dataset(\"s3://anonymous@bio230014-bucket01/challenges/scores/parquet/project_id=neon4cast/duration=P1D/variable=temperature/model_id=hotdeck?endpoint_override=sdsc.osn.xsede.org\")\ndf <- all_results |> dplyr::collect()\n\n```\n       \n\nYou can use dplyr operations before calling `dplyr::collect()` to `summarise`, `select` columns, and/or `filter` rows prior to pulling the data into a local `data.frame`. Reducing the data that is pulled locally will speed up the data download speed and reduce your memory usage.\n\n\n"
    },
    "4": {
      "type": "application/x-parquet",
      "title": "Database Access for Daily Dissolved_oxygen",
      "href": "s3://anonymous@bio230014-bucket01/challenges/scores/parquet/project_id=neon4cast/duration=P1D/variable=oxygen/model_id=hotdeck?endpoint_override=sdsc.osn.xsede.org",
      "description": "Use `arrow` for remote access to the database. This R code will return results for this variable and model combination.\n\n### R\n\n```{r}\n# Use code below\n\nall_results <- arrow::open_dataset(\"s3://anonymous@bio230014-bucket01/challenges/scores/parquet/project_id=neon4cast/duration=P1D/variable=oxygen/model_id=hotdeck?endpoint_override=sdsc.osn.xsede.org\")\ndf <- all_results |> dplyr::collect()\n\n```\n       \n\nYou can use dplyr operations before calling `dplyr::collect()` to `summarise`, `select` columns, and/or `filter` rows prior to pulling the data into a local `data.frame`. Reducing the data that is pulled locally will speed up the data download speed and reduce your memory usage.\n\n\n"
    }
  }
}
